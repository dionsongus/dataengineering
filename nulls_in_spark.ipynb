{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nulls in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"Nulls in Spark\")\n",
    "    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulls and data types\n",
    "Besides the null, which corresponds to a python None,  there're also defacto nulls like NaN and ''.\n",
    "Note the NaN is a float or double data type. It cannot be part of an integer column nor a string column in spark. \n",
    "And '' can only show up in a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1., None, 'Tom'), (None, 2, None), (float('nan'), 2, '')], (\"a\", \"b\", \"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|   a|   b|   c|\n",
      "+----+----+----+\n",
      "| 1.0|null| Tom|\n",
      "|null|   2|null|\n",
      "| NaN|   2|    |\n",
      "+----+----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[a: double, b: bigint, c: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of nulls\n",
    "F.isnull and df.column.isNull() picks up nulls but not NaN nor ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+\n",
      "|(a IS NULL)|(b IS NULL)|(c IS NULL)|\n",
      "+-----------+-----------+-----------+\n",
      "|      false|       true|      false|\n",
      "|       true|      false|       true|\n",
      "|      false|      false|      false|\n",
      "+-----------+-----------+-----------+\n",
      "\n",
      "+-----------+-----------+-----------+\n",
      "|(a IS NULL)|(b IS NULL)|(c IS NULL)|\n",
      "+-----------+-----------+-----------+\n",
      "|      false|       true|      false|\n",
      "|       true|      false|       true|\n",
      "|      false|      false|      false|\n",
      "+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr = [F.isnull(column) for column in df.columns]\n",
    "df.select(*expr).show()\n",
    "df.select(df.a.isNull(), df.b.isNull(),df.c.isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.isnan() picks up NaN's only, and a null will not trigger an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|isnan(a)|isnan(b)|isnan(c)|\n",
      "+--------+--------+--------+\n",
      "|   false|   false|   false|\n",
      "|   false|   false|   false|\n",
      "|    true|   false|   false|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr = [F.isnan(column) for column in df.columns]\n",
    "df.select(*expr).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.col(column)=='' picks up '''s only, a null does not trigger an error, a type mismatch triggers a null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|(a = )|(b = )|(c = )|\n",
      "+------+------+------+\n",
      "|  null|  null| false|\n",
      "|  null|  null|  null|\n",
      "|  null|  null|  true|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr = [F.col(column)=='' for column in df.columns]\n",
    "df.select(*expr).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts with nulls\n",
    "F.count() does not count nulls but counts NaNs and ''s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|count(a)|count(b)|count(c)|\n",
      "+--------+--------+--------+\n",
      "|       2|       2|       2|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr = [F.count(column) for column in df.columns]\n",
    "df.select(*expr).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore needs to subtract NaN and '' explicitly to get the true null rate. Note F.col(column)=='' triggers null in non-string columns and needs to be treated separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+---------------------------------------+-------------------------------------+\n",
      "|(count(a) - sum(CAST(isnan(a) AS INT)))|(count(b) - sum(CAST(isnan(b) AS INT)))|(count(c) - sum(CAST((c = ) AS INT)))|\n",
      "+---------------------------------------+---------------------------------------+-------------------------------------+\n",
      "|                                      1|                                      2|                                    1|\n",
      "+---------------------------------------+---------------------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_columns = [column for (column, type) in df.dtypes if type=='string']\n",
    "non_string_columns = [column for (column, type) in df.dtypes if type!='string']\n",
    "expr1 = [F.count(column)-F.sum(F.isnan(column).cast('int')) for column in non_string_columns]\n",
    "expr2 = [F.count(column)-F.sum((F.col(column)=='').cast('int')) for column in string_columns]\n",
    "df.select(*expr1+expr2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for column b, the adjustment is not needed because as an integer column, it cannot contain NaN nor ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
